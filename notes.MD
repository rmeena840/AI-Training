# There are 3 types of gradient descents:
# 1. Batch Gradient Descent
# 2. Stochastic Gradient Descent
# 3. Mini Batch Gradient Descent
# 4. Chain Rule
# 5. Tensorboard for visualization and debugging
# 6. Neuroevolutionary Algorithm or NEAT


# Important notes:
# 1. Feature scaling should be done after train and test split.
# 2. Never use fit on test data. Use fit_transform on train data but never use this with test data. You can use transform.
# 3. Whener there D number of dummy variables, then there should be D-1 number of dummy variables.
# 4. Check this link: https://drive.google.com/drive/folders/1OFNnrHRZPZ3unWdErjLHod8Ibv2FfG1d
# useful data set along with examples are available
# 5. Feature scaling is not needed for decision tree and random forrest.
# 6. Mapping to higher dimension can be computer intensive.

